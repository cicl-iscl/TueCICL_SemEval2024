{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "import pandas as pd\n",
    "import typing as T\n",
    "import string\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f25e893fd70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        return torch.device('mps')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    train = pd.read_json(\"./data/subtaskA_train_monolingual.jsonl\", lines=True)\n",
    "    dev = pd.read_json(\"./data/subtaskA_dev_monolingual.jsonl\", lines=True)\n",
    "    return train, dev\n",
    "\n",
    "train, dev = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHITESPACE = \"<WS>\"\n",
    "PUNCTUATION = \"<PUNCT>\"\n",
    "DIGIT = \"<DIGIT>\"\n",
    "UNK = \"<UNK>\"\n",
    "SENT_TERMINATE = \"<SENT_TERMINATE>\"\n",
    "\n",
    "BOS = \"<BOS>\"\n",
    "EOS = \"<EOS>\"\n",
    "PAD = \"<PAD>\"\n",
    "\n",
    "def map_char(char: str):\n",
    "    sentence_ending = [\".\", \"!\", \"?\"]\n",
    "    if char.isspace():\n",
    "        return WHITESPACE\n",
    "    if char in sentence_ending:\n",
    "        return SENT_TERMINATE\n",
    "    if char in string.punctuation:\n",
    "        return PUNCTUATION\n",
    "    if char in string.digits:\n",
    "        return DIGIT\n",
    "    if char not in string.printable:\n",
    "        return UNK\n",
    "    return char\n",
    "\n",
    "def build_vocab(train_set: pd.DataFrame):\n",
    "    vocab = set()\n",
    "    for _, series in train_set.iterrows():\n",
    "        text: str = series[\"text\"]\n",
    "        tokens: T.List[str] = [*text.lower().strip()]\n",
    "        tokens = [map_char(token) for token in tokens]\n",
    "        for token in tokens:\n",
    "            vocab.add(token)\n",
    "    vocab = list(vocab)\n",
    "    \n",
    "    vocab.append(BOS)\n",
    "    vocab.append(EOS)\n",
    "    vocab.append(PAD)\n",
    "    \n",
    "    word2idx = {\n",
    "        word: idx for idx, word in enumerate(vocab)\n",
    "    }\n",
    "    idx2word = {\n",
    "        idx: word for idx, word in enumerate(vocab)\n",
    "    }\n",
    "    return word2idx, idx2word, vocab\n",
    "\n",
    "def get_vocab():\n",
    "    fp = \"./data/charlm_vocab.pkl\"\n",
    "    try:\n",
    "        with open(fp, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    except:\n",
    "        train, _ = get_data()\n",
    "        res = build_vocab(train)\n",
    "        with open(fp, \"wb\") as f:\n",
    "            pickle.dump(res, f)\n",
    "        return res\n",
    "    \n",
    "word2idx, idx2word, vocab = get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_tokens(text:str):\n",
    "    tokens: T.List[str] = [*text.lower().strip()]\n",
    "    tokens = [map_char(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def tokenize(texts: T.List[str], max_len=None, add_special_tokens=True):\n",
    "    tokenized_texts = [get_text_tokens(t) for t in texts]\n",
    "    \n",
    "    longest_len = max([len(t) for t in tokenized_texts])\n",
    "    if max_len and max_len < longest_len:\n",
    "        longest_len = max_len\n",
    "    tokenized_texts = [t[:longest_len] for t in tokenized_texts]\n",
    "    \n",
    "    tokens, attentions = [], []\n",
    "    for tokenized_text in tokenized_texts:\n",
    "        \n",
    "        pad_amount = longest_len - len(tokenized_text)\n",
    "        if add_special_tokens:\n",
    "            tokenized_text = [BOS] + tokenized_text + [EOS]\n",
    "        \n",
    "        tokenized_text += [PAD] * (pad_amount)\n",
    "        tokens.append([word2idx[token] for token in tokenized_text])\n",
    "        attentions.append([1 if token != PAD else 0 for token in tokenized_text])\n",
    "    return torch.tensor(tokens, device=device), torch.tensor(attentions, device=device)\n",
    "\n",
    "def decode(tokens: T.List[T.List[int]]):\n",
    "    return [[idx2word[token] for token in tokenized_text] for tokenized_text in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskA_Dataset(Dataset):\n",
    "    def __init__(self, split=\"train\") -> None:\n",
    "        if split == \"train\":\n",
    "            self.data = pd.read_json(\"./data/subtaskA_train_monolingual.jsonl\", lines=True)\n",
    "        else:\n",
    "            self.data = pd.read_json(\"./data/subtaskA_dev_monolingual.jsonl\", lines=True)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data.iloc[index]\n",
    "        text, label, _id = item[\"text\"], item[\"label\"], item[\"id\"]\n",
    "        return text, label, _id\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAX char ~ 200.000\n",
    "\n",
    "MEAN char ~ 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLM(nn.Module):\n",
    "    def __init__(self, vocab_size=None, emb_size=8, hidden_size=1024, num_layers=1) -> None:\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_size)\n",
    "        self.lstm = nn.LSTM(\n",
    "            hidden_size=hidden_size,\n",
    "            input_size=emb_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.lstm2lm = nn.Linear(hidden_size, vocab_size)\n",
    "        self.lstm2class = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def _get_means(self, tensors, attentions):\n",
    "        # Function computes embedding averages, but taking out the PAD tokens, as they should not contribute to MEAN.\n",
    "        # Written kinda complicated to avoid copying tensors as much as possible, a previous solution was extremely slow because of\n",
    "        # such copy and slice operations\n",
    "        batch_size, seq_len, hidden_size = tensors.shape\n",
    "        filter = attentions.reshape((batch_size, seq_len, 1)).expand((batch_size, seq_len, hidden_size))\n",
    "        filtered = torch.where(filter > 0, tensors, 0)\n",
    "        l = attentions.sum(dim=1).reshape(-1, 1)\n",
    "        s = tensors.sum(dim=1)\n",
    "        return s / l\n",
    "    \n",
    "    def forward(self, input_ids, attention):\n",
    "        embedded = self.emb(input_ids)\n",
    "        out, _ = self.lstm(embedded)\n",
    "        lm_out = self.lstm2lm(out)\n",
    "        lm_out = F.log_softmax(lm_out, dim=-1)\n",
    "        means_for_classification = self._get_means(out, attention)\n",
    "        classification_out = self.lstm2class(means_for_classification)\n",
    "        classification_out = F.log_softmax(classification_out, dim=-1)\n",
    "        return lm_out, classification_out\n",
    "\n",
    "def collate_fn(data):\n",
    "    labels = [i[1] for i in data]\n",
    "    texts = [i[0] for i in data]\n",
    "    ids = [i[2] for  i in data]\n",
    "    max_len = 20_000\n",
    "    input_ids, attentions = tokenize(texts, max_len=max_len)\n",
    "    return input_ids, attentions, torch.tensor(labels, device=device), torch.tensor(ids, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset):\n",
    "    dev_dataloader = DataLoader(dataset, shuffle=False, batch_size=10, collate_fn=collate_fn)\n",
    "    y_pred = []\n",
    "    y_gold = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attentions, labels, _ in dev_dataloader:\n",
    "            _, out = model(input_ids, attentions)\n",
    "            for i in range(out.shape[0]):\n",
    "                pred = torch.argmax(out[i]).item()\n",
    "                y_pred.append(pred)\n",
    "                y_gold.append(labels[i].item())\n",
    "    \n",
    "    r = classification_report(y_gold, y_pred)\n",
    "    print(r)\n",
    "    return r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_checkpoint(model, optimizer, epoch, prefix=\"classifier\", report=None):\n",
    "    try:\n",
    "        os.mkdir(\"checkpoints\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    checkpoint = {\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        \"report\": report\n",
    "    }\n",
    "    torch.save(checkpoint, f\"checkpoints/{prefix}_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isnan\n",
    "ls = None\n",
    "\n",
    "def train(model=None, optimizer=None, dataloader=None, n_epochs=5,start_epoch=1, checkpoint_prefix=None):\n",
    "    lm_criterion = nn.NLLLoss(reduction=\"mean\")\n",
    "    cl_criterion = nn.NLLLoss(reduction=\"sum\")\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in range(start_epoch, n_epochs+1):\n",
    "        with tqdm(total=len(dataloader)) as pbar:\n",
    "            pbar.set_description(f\"Epoch {epoch}\")\n",
    "            losses = []\n",
    "            for input_ids, attentions, labels, text_ids in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                lm_out, classifier_out = model(input_ids, attentions)\n",
    "                loss = torch.tensor(0, dtype=torch.float32, device=device)\n",
    "                \n",
    "                # ------------------\n",
    "                # LM loss\n",
    "                # ------------------\n",
    "                \n",
    "                for i in range(input_ids.shape[0]):\n",
    "                    if labels[i].item() == 0:\n",
    "                        # only train LM on human texts\n",
    "                        y_pred = lm_out[i, :-1]\n",
    "                        y_gold = input_ids[i, 1:]\n",
    "                        loss_update = lm_criterion(y_pred, y_gold)\n",
    "                        if isnan(loss_update.item()):\n",
    "                            print(\"NAN loss detected, do not backprop\")\n",
    "                            continue\n",
    "                        loss += loss_update\n",
    "                \n",
    "                # ------------------\n",
    "                # Classifier loss\n",
    "                # ------------------\n",
    "                loss_update = cl_criterion(classifier_out, labels)\n",
    "                loss += loss_update\n",
    "                \n",
    "                # ------------------\n",
    "                # Backprop\n",
    "                # ------------------\n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.update(1)\n",
    "\n",
    "            print(\"LOSS\", sum(losses) / len(losses))\n",
    "            report = evaluate(model, TaskA_Dataset(split=\"dev\"))\n",
    "            make_checkpoint(model, optimizer, epoch, prefix=checkpoint_prefix, report=report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "CHECKPOINT MODEL EVAL\n",
      "-------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.78      0.57      2500\n",
      "           1       0.20      0.06      0.09      2500\n",
      "\n",
      "    accuracy                           0.42      5000\n",
      "   macro avg       0.33      0.42      0.33      5000\n",
      "weighted avg       0.33      0.42      0.33      5000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:  38%|█████████████████████████▌                                         | 5715/14970 [1:08:11<1:57:41,  1.31it/s]"
     ]
    }
   ],
   "source": [
    "model = CharLM(\n",
    "    vocab_size=len(vocab),\n",
    "    hidden_size=256,\n",
    "    num_layers=3\n",
    ")\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=0.005)\n",
    "start_epoch = 1\n",
    "checkpoint_prefix=\"charlm_256_3\"\n",
    "\n",
    "cp_file = \"charlm_256_3_4.pt\"\n",
    "CP = f\"checkpoints/{cp_file}\" if cp_file else None\n",
    "\n",
    "if CP:\n",
    "    checkpoint_data = torch.load(CP)\n",
    "    model.load_state_dict(checkpoint_data[\"model\"])\n",
    "    optimizer.load_state_dict(checkpoint_data[\"optimizer\"])\n",
    "    start_epoch = checkpoint_data[\"epoch\"] + 1\n",
    "    print(\"-------------------------\")\n",
    "    print(\"CHECKPOINT MODEL EVAL\")\n",
    "    print(\"-------------------------\")\n",
    "    if \"report\" in checkpoint_data:\n",
    "        print(checkpoint_data[\"report\"])\n",
    "    else:\n",
    "        evaluate(model, TaskA_Dataset(split=\"dev\"))\n",
    "    print()\n",
    "\n",
    "\n",
    "ds = TaskA_Dataset(split=\"train\")\n",
    "\n",
    "loader = DataLoader(\n",
    "    ds,\n",
    "    shuffle=True,\n",
    "    batch_size=8,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "losses = train(\n",
    "    model=model, \n",
    "    optimizer=optimizer, \n",
    "    dataloader=loader, \n",
    "    n_epochs=5, \n",
    "    start_epoch=start_epoch, \n",
    "    checkpoint_prefix=checkpoint_prefix\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
